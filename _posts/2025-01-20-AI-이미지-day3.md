---
layout: page
title: "Ai 심화 Day3"
description: ""
headline: ""
tags: [python, 파이썬, torchtext, pytorch, 파이토치, 전처리, data science, 데이터 분석, 딥러닝, 딥러닝 자격증, 머신러닝, 빅데이터]
categories: 
comments: true
published: true
---

Conv2d

filter bias

 spatial dimensions == depth
  
<https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html>

![](https://blog.kakaocdn.net/dn/buTDig/btrUNWinaGI/Up3sBWkF1divFGgkP4DF2k/img.gif)

Naive Convolution [ 1 ]

![](https://blog.kakaocdn.net/dn/bpzdOE/btrUSukFrys/m8pk4doUidUAMASsLD5Ez0/img.gif)

Atrous Convolution [ 1 ]

![](https://blog.kakaocdn.net/dn/bjS7OO/btrUNqRBVaK/civUAMDkqkDr2Y1MYM1yb1/img.gif)

Transposed Convolution [ 1 ]

Unet 이해

_class_torch.nn.Conv2d(_in_channels_, _out_channels_, _kernel_size_, _stride=1_, _padding=0_, _dilation=1_, _groups=1_, _bias=True_, _padding_mode='zeros'_, _device=None_, _dtype=None_)

![https://wandb.ai/ayush-thakur/dl-question-bank/reports/Intuitive-understanding-of-1D-2D-and-3D-convolutions-in-convolutional-neural-networks---VmlldzoxOTk2MDA](https://velog.velcdn.com/images/not12m10/post/1397fbde-00d8-4d8b-8c5c-62bf9acf7cad/image.gif)

![https://www.geeksforgeeks.org/apply-a-2d-convolution-operation-in-pytorch/](https://velog.velcdn.com/images/not12m10/post/f3c02918-fca1-4c29-8dde-ff0aa888ab76/image.gif)

----

## 1. 함성곱 신경망

(Global) average pooling

1D

시간축으로

2D

이미지

3D

필터도 3차원을 가진

3D 입략을 갖는 2D 합성곱

fasion_size 28 by 28

batch norm 알고리즘 분석

- <https://eda-ai-lab.tistory.com/406>

논문 읽고 분석하기

- <https://arxiv.org/abs/1505.04597>

## FCN (Fully Convolutional Networks)

pixelwise prediction

- upsampling을 하여 dense map을 얻는 방법으로 **2가지 방법**이 더 소개된다.
-

- feature map 객채수를 동일하게 맞춰 준다
- 고양이에 대한
- heatmap이 낮은 걸 upsamping 시킨다 -feature map 을 만들어 준다
- 1. convlution 통해서 feature 추출하고 2 동일하게 맞추고 3번단계에서는 upsampling 시키고 4. 최종 featuremap과 정답과 학습을 한다.

VGN 224 by 224 -(pooling)-> 112 by 112 -> 56 by 56 -> 28 by 28 -> 14 by 14 -> 7 by 7 -> 1 by 1

coarse(대려적인) 정보를 얻고 있다.

FCN fully connected layer 없고 1 by 1  슬라이드에 표현은 없지만 Relu 함수를 통해서 출력을 한다.

pooling 대신에 stride 2 를 사용하여 줄여주는 경우도 있다. (확인해보기)

작은 픽셀 크기를 크게 만들면 성능이 떨어진다.

FCN-32s, FCN-16s, FCN-8s

conv conv pooling -> conv conv pooling -> conv conv conv pooling -> conv conv conv pooling -> 1 by 1 conv

중간에 1 by 1 conv featuremap  사용한다 4번이 6번보 featureamap 조금더 중용한 정보를 얻는다(왜? 점점 줄어들어줄)

그래서 6번에서의 upsampling 한거랑 4번의 skip connection을 통해서 최종 출력을 한다.

![](https://miro.medium.com/max/700/1*5LhYXkhBg6kwbR1zN5Eg8g.png)

![alt text](https://wikidocs.net/images/page/143443/FCN-16S.png)

![](https://wikidocs.net/images/page/143443/FCN-8S.png)

upsampin 하면 해상도가 떨어져 안좋아서

Encoder 와 Decode 사용해서

nnUnet 의료계에서 탑으로 자리 매김 하고 있다.

## Encoder-Decoder 구조

고생상도 이미지를 Decoder 에 가지고 있다.

Encoder 정보를 압축하고

Decoder 정보를 풀어준다.

Decoder 원래 정볼르 복원하면서

upsamping techniques

pooling 한걸 다시 unpooling  한거

transpose convlution

![](https://velog.velcdn.com/images%2Fhayaseleu%2Fpost%2F8abde504-c3b1-4a40-a17d-16ad230ccead%2F1_WpOcRWlofm0Z0EDUTKefzg.gif)![](https://velog.velcdn.com/images%2Fhayaseleu%2Fpost%2F36c9c660-27c3-40f3-a08c-335bf67610c1%2F1_34_365CJB5seboQDUrbI5A.gif)![](https://velog.velcdn.com/images%2Fhayaseleu%2Fpost%2F9457f703-acb1-443f-a450-8f1f834396dc%2F1_gXAcHnbTxmPb8KjSryki-g.gif)![](https://velog.velcdn.com/images%2Fhayaseleu%2Fpost%2F8abde504-c3b1-4a40-a17d-16ad230ccead%2F1_WpOcRWlofm0Z0EDUTKefzg.gif)

Unet 구조는 양쪽으로 대칭 구조

각 step 마다 풀링 이 포함되어 있다.
다운 샘플링 할때마다 2배식 채널수 증가

convolution & ReLU (최근에 ReakyReLU 사용하는 추세)

Pooling()

64 128 256 512 1024

bottlneck encoder 분분에 압축 되어 있다.
2 by2 up convolution

Decoder(Expanding Path) 심화

Transposed Convolution (Deconvolution)

업샘플링 + 학습

bottleneck 및 전체 흐름

bottleneck
인코더를 통해 가장 축소된 해상도 (가장 깊은 레이어)

1. BinaryCrossEntropy(BCE)
CrossEntropy 인데 Binary 인 경우 사용한다 픽셀이 foreground 인지 background 인지

2. Dice Loss

- 두 이미지 간의 유사도를 측정하는 손실 함수
- p는 예측 값 (0~1 사이) prediction
- y는 실제 값 (0~1 사이) ground truth -> 실제 값
- prediction 과 ground truth 가 얼마 만큼 겹치는가?

- overlap

1. Focal Loss값

<https://minimin2.tistory.com/179>

Hard Example 가중치

1. Hard Example Mining (OHEM, Online Hard Example Mining)
2. Weighted BCE
3. Focal Loss

pixel 별로 분할 하는것이다.

2.wieighted BCE는 적은 양에 클래스에 더 큰 가중치를 준다.

3. 예측 확율 하드 example에 가중치를 준다 .  잘틀리는 것에 더 큰 가중치를 주어서 잘맞게 하지만 단점은 밸런스가 깨진다.

Dice coefficient는 P (prediction) 과 y (ground truth) 각각 더하고 곱한 후

IoU (Intersection over Union) 일반적으로 사용되는 손실 함수적

Dice는 의료 영상

Precision

recall 실제  positive를 고려한다.

**2. 정확도(Precision)**

True로 **예측한** 분석대상 중에서 **실제 값**이 True인 비율을 말하며, 모형의 정확성을 나타내는 지표가 된다. 정확도가 높다는 것은 False Positive(**실제 False를 True로 잘못 예측**) 오류가 적다는 말이다.

![](https://www.simplilearn.com/ice9/free_resources_article_thumb/5-precision.JPG)

**3. 재현율(Recall)**

**실제 값**이 True인 분석대상 중에서 True로 **예측**하여 모형이 적중한 비율을 말하며, 모형의 완전성을 나타내는 지표이다. 재현율이 높다는 것은 False Negative(**실제 True를 False로 잘못 예측**) 오류가 낮다는 뜻이다

![](https://www.simplilearn.com/ice9/free_resources_article_thumb/recall.JPG)

> [!의료 데이터에서의 confusion matrix]
>  의료 데이터에서는 **Recall 이 중요**하다 왜냐하면, 병걸린 사람을 검사했을 때 오진이 나오면 안되기 때문이다. 기본적으로 병원에서는 True/False(병의 유무)를 여러단계를 거쳐서 검사를 진행한다. 우선은 비교적 간단하지만, 정확도가 떨어지는 test를 먼저 진행한다. 그리고 병에 걸릴 가능성이 있다면 재검사를 통해 정확도가 높은 test를 진행는 방식을 사용한다. 예를들면, MRI를 찍고 다른 가능성이 있으면 혈액검사 같은 추가 검사를 진행하는 것과 같다. 정리하면, 처음부터 모든 검사를 다할 수없으니 간단한 검사부터 해서 좁혀나가는 것이다. 이러한 방식은 Recall이 좋아야 병을 찾아 나갈 수 가 있다.  
>  물론 최종적으로는 Recall과 Precision이 둘다 좋은 비싼 방법을 사용할 것이다. 그러나 초반의 경우, 데이터를 쉽게 얻을 수 있는 것들을 조합하거나 recall을 더 중요시 한다. 여기서 주의 할 점이 Recall만 100프로 몰빵을 하면, Precision이 0이 될 수도 있다. 예를들면, 무한대의 환자가 왔을때 너 무조건 병이 있다고 하면 Recall은 100%가 된다. 하지만 Precision은 n/무한대 가 되므로 0으로 가까워진다. 병안 걸린 사람도 병린사람이 될기도 한다. 따라서 **recall을 100프로 만드는 것은 바람직하지 않고, 0.9나 95%이상으로 유지하면서 precision을 떨어뜨리지 않는것이 중요하다.**

왜 unet 에서 왜 좋은 성능을 보이는가?

1. 소량 데이터로도 괜찮은 성능을 보인다.괜
2. 경계 정보 복원에 유리 하다
3. 원 논문에서 ISBI Cell Tracking 등에서 좋은 성능을 보여준다.

데이터 전처리
정규화

데이터 증강
회전, 플립, 스케일, 노이증 추가
의료 영상 특성상, 고도한 왜곡은 주의

과접합 방지

- Regularization , Dropout, Early Stopping
- cross validation (데이터가 적을때 유효)

attention unet

- attention gate 주요 영역 강조,

SegNet

DeepLap

PSPNet

unet 핵심 정리
Encoder - Decoder + skip connection = 정밀 분할

- 의료 영ㅇ에서 탁월한 성능, 다양한 확장형 모델 존재
- 소량 데이터, 경계 정보에 매우 효과적

Q1) skip connection 제거 시 성능 차이?

Q2) 고해상도 이미지 메모리 문제 해결법?

Q3) 다른 세그멘테이션 모델과의 성는 비교?
