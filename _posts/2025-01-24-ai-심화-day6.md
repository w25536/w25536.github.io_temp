---
layout: page
title: "AI 심화 day6"
description: ""
headline: ""
tags: [python, 파이썬, torchtext, pytorch, 파이토치, 전처리, data science, 데이터 분석, 딥러닝, 딥러닝 자격증, 머신러닝, 빅데이터]
categories: 
comments: true
published: true
---



Transformer 이해 

Non-vision specific model
-Typically applied to 1-D sequence data 


Transformer "encoder"
- A stack of alternating self-attention and MLP blocks
- Residual and LayerNorm 

Transformer "decoder"
- A slightly more involved archetecture useful when the ouput space is different from the input space 



![alt text](http://jalammar.github.io/images/t/transformer_decoding_2.gif)


## Q, K, V 어텐션 메커니즘

- **Q (Query)**: 디코더의 숨겨진 상태로, 현재 처리 중인 단어에 대한 정보를 담고 있습니다. (decoder 의 숨겨진 상태)
- **K (Key)**: 인코더의 숨겨진 상태로, 입력 시퀀스의 각 단어에 대한 정보를 담고 있습니다. (encoder 의 숨겨진 상태)
- **V (Value)**: 인코더의 숨겨진 상태로, 실제 어텐션 결과에 사용되는 값입니다. (encoder 의 숨겨진 상태)

어텐션 메커니즘은 Query(Q)와 Key(K) 간의 유사도를 계산하여 해당 Value(V)에 가중치를 부여합니다. 이를 통해 디코더는 입력 시퀀스의 중요한 부분에 집중할 수 있습니다.

특히, Q와 K의 내적(dot product)을 통해 어텐션 점수를 산출하고, 이를 소프트맥스(softmax) 함수를 이용해 확률로 변환합니다. 높은 어텐션 값은 높은 연관성을 나타내며, 해당 Value에 더 큰 영향을 미칩니다.




encoder 하는 역활은

context vector을 LSTM에 전달하고, 디코더를 학습시킬 때 teacher forcing을 적용합니다. 디코더는 단순히 context vector만 사용하는 대신, 인코더의 모든 은닉 상태를 참조하여 각 단계에서 중요한 정보를 선택적으로 활용할 수 있습니다. 이러한 방식이 바로 어텐션(attention) 기법입니다. 어텐션 메커니즘을 통해 디코더는 입력 시퀀스의 전체 정보를 고려하여 더 정확하고 효과적인 출력을 생성할 수 있습니다.



Self attention  왜? K 에서 부터 encoder 하닌깐 

layer by norm 이  n 번 반복 된다. 



Q, K, V 를 학습한다 

multi-head가 왜 붙었어? head가 여려개 있다. 


 // Start of Selection
Convolutional Neural Networks (CNNs)은 컴퓨터 비전 분야에서 핵심적인 역할을 담당하는 신경망 구조로, 입력 이미지로부터 공간적 계층 구조의 특징을 자동적이고 적응적으로 학습하는 데 뛰어납니다. CNN은 필터(커널)를 사용하여 입력 데이터에 걸쳐 합성곱 연산을 수행함으로써 지역 패턴을 효과적으로 포착하며, 이를 통해 이미지 분류, 객체 검출, 세분화 등 다양한 작업에서 우수한 성능을 발휘합니다.

반면에 Transformer는 원래 자연어 처리(NLP) 분야에서 도입된 구조로, 주의 메커니즘(attention mechanism)을 활용하여 시퀀스 데이터 내의 장기적인 의존성과 문맥 관계를 모델링합니다. 자기 주의(Self-Attention) 메커니즘을 통해 Transformer는 입력 데이터의 서로 다른 부분 간의 중요도를 동적으로 평가할 수 있으며, 이는 전통적인 CNN이나 순환 신경망(RNN)에 비해 더욱 유연하고 강력한 표현력을 제공합니다.

교수의 시각에서 볼 때, CNN과 Transformer의 통합은 두 아키텍처의 강점을 동시에 활용하려는 시도라 할 수 있습니다. CNN은 지역적이고 공간적인 특징 추출에 탁월한 반면, Transformer는 글로벌한 관계와 문맥 정보를 효과적으로 캡처할 수 있습니다. 이러한 하이브리드 접근 방식은 이미지 인식 및 컴퓨터 비전 작업에서 CNN의 특징 추출 능력과 Transformer의 문맥 인식 능력을 결합함으로써 더욱 정교하고 정확한 모델을 구현할 수 있게 합니다. 예를 들어, CNN을 통해 추출된 특징 맵을 Transformer의 주의 메커니즘과 결합하여 복잡한 이미지 내의 다양한 객체 간의 관계를 이해하고, 이를 기반으로 보다 정밀한 예측을 가능하게 합니다.


attention ? 
 input에 대해서 뭐가 중요하는지 weight를 정해는 얘다 



multi-head 정보를 모두 Feed Forward Neural Network (FFNN)를 통해 처리합니다. 일반적으로 FFNN이라고 칭하며, 이는 각 어텐션 헤드에서 추출된 특징을 통합하여 다음 층으로 전달하는 역할을 합니다. Multi-head는 여러 개의 어텐션 헤드를 의미하며, 각 헤드는 서로 다른 행렬을 사용하여 입력 데이터의 다양한 측면을 학습합니다. 이러한 다중 헤드 구조는 모델이 다양한 표현 공간에서 정보를 효과적으로 처리할 수 있도록 도와줍니다.

수

