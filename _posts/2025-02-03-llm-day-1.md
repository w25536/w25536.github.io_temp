---
layout: page
title: LLM day 1
description: ""
headline: ""
tags:
  - python
  - 파이썬
  - torchtext
  - pytorch
  - 파이토치
  - 전처리
  - data
  - science
  - 데이터
  - 분석
  - 딥러닝
  - 딥러닝
  - 자격증
  - 머신러닝
  - 빅데이터
categories: llm
comments: true
published: true
---

김명욱 강사님 

5000차원


Vectorization -> Vector Dataset -> XXX차원 데이터



## Tokenizer

https://platform.openai.com/tokenizer

![](https://cdn.mathpix.com/snip/images/pOZLDQV0dlOtvlgHPNlgda6G4TUcG8cNias2e8IaUBo.original.fullsize.png)



![](https://cdn.mathpix.com/snip/images/Nie7JxxMj4Pdvk6N8VO6TP0szn7OdXLwgFmn5SYSLKI.original.fullsize.png)

tokenized 단어를 보면 한단어이지만 ized 붙으면서 의미가 달라지기 떄문에 따로 처리함 


1.03 하면 대충 단어수가 맞음~ 

영어는 그러저럭 처리를 하지만 한국어는? 


![](https://cdn.mathpix.com/snip/images/OEysQOomNPwKD2Z_Hi-reNcMUV-lHt6Zd448rZxWGYc.original.fullsize.png)


엉망으로 나온다 유니코드를 동장 하는거는 tokenizer는  GPU 파워로 돌리는거다. 


![](https://cdn.mathpix.com/snip/images/8n747fmz6gzKQsM3NYSFspqhRpGN7Se8NzFuHYGskBw.original.fullsize.png)

77% 토큰나이저 개선되어 위에 보면 그나마 괜찮다.  전 30 tokens 사용되고 보면 현재는 18토큰이 사용된다.

다음은 가격을 알아보자 ~


https://openai.com/api/pricing/


![](https://cdn.mathpix.com/snip/images/AzEruQC7bhmFw8dcIOFhI-5vajGNBuJUsoWEB-ZN03I.original.fullsize.png)


transformer encoder decoder 디코드 부분이 훨씬크고 답을 처리하면 가격이 훨씬 비싸다 


Pring with Batch API 
한꺼번에 처리해ㅓ 싸다 예를 들면 즉시 처리할 필요가 없는거 같은 경우 
검열 같은 경우 batch로 돌린다 

상담 같은 경우에는 real time 으로 처리해야 한다. 



유명한 언어 모델들을 모아서 평가하고 기록 하는 사이트 이다 주기적으로 방문해서 확인해 보자 


https://artificialanalysis.ai/


DeepSeek R1  - 0 강화 학습으로 학습이 시키면 0 이 붙는다 


SLM 모델은  mini 

DeepSeek R1 모델이 o1 모델을 사용 했다는 근거 발견되어 소송을 준비 중이라고 한다...

구글은 학습을 시키는 메카니즘이 어려워서 천천이 QUALITY를 높이고 있는 중이다. 

Gemini 가 억지로 따라 오다가 무리 할 

전세계 말이 안돼는 단어만 모아서 Gemini라는 단어가 생성 했다고 한다. 

Claude 뒤를 봐주는 회사 없어서 약하다

bing은 ... 생략 ㅋ


SPEED  높을 수로 좋다고 한다. 

어쨰든 돌아와 토큰으로 LLM은 움직인다 


4070 쓸수 없는이유 vram이 낮아서 돌릴 수 없다.  하지만 DeepSeek은 가능하다 설명하다


애저에서 한번 만들어보자 

![](https://cdn.mathpix.com/snip/images/UxoekKZ7f8xQgl8-rKY-b0cdJw_PwEEH8q5LO68OR4w.original.fullsize.png)


![](https://cdn.mathpix.com/snip/images/UxoekKZ7f8xQgl8-rKY-b0cdJw_PwEEH8q5LO68OR4w.original.fullsize.png)


![](https://cdn.mathpix.com/snip/images/bTOhh6TO-4Ghq4Zd05CxHmH8bBdMU6nKJnKB6ikbI5A.original.fullsize.png)



![](https://cdn.mathpix.com/snip/images/c1gSC9FPZZ7CZF4yOkPZtYhHRRAjtFn9XhcVVNgnZXw.original.fullsize.png)


![](https://cdn.mathpix.com/snip/images/rBsvHqkh-gXfvrF014VtPAnJSyxfoPDyFd70dAONDlA.original.fullsize.png)


미세 조정된 모델 배포 = fine-tunning 
1. 외만하면 다른 방법을 사용하는게 좋다
2. fine tunnning할때는 사투리
3. 데이터는 json 형태로 만들어야 되고 그 시간은 프로젝트 기간의 80% 시간을 잡아 먹으니 하지마라
4. fine-tunning 음식 데이터 200만원 나옴 하지 않는게 좋다 




![](https://cdn.mathpix.com/snip/images/GkXls1BY52WZt3hFE4vH3kWDV1HGWy-uAiZV_RvaFLA.original.fullsize.png)


preview 
01  이런건 비용 많이 나오니 사용하지 말아라 



![](https://cdn.mathpix.com/snip/images/TEG_mPPYxvmwb-9jcMLVvFz8LxTxbLnIKwp2HHRUUYc.original.fullsize.png)


chat completion

![[CleanShot 2025-02-03 at 12.00.51@2x.png]]


![](https://cdn.mathpix.com/snip/images/0D2M2YXWwO8nsZapzREbDSAPhFgWZaOidQ8sOJeZbBU.original.fullsize.png)


전체 일괄 처리 == batch
언제 결과가 나올지 모른다. 



![](https://cdn.mathpix.com/snip/images/B_awp9lugHcls7Mgy2IKR61d5Phf4IemLUGMv2NJJro.original.fullsize.png)

모델 버전을 테스트해보고 


분당 토큰 속도 = RPM 

Request per miniutes 토큰가지고 속도를 제한 할 수 있음 
높일 수록 속도 제한을 풀어 주는거라 한다 
500 서버 error 

콘테츠 필터? 
