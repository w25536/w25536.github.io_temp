---
layout: page
title: "Ai 심화 Day3"
description: ""
headline: ""
tags: [python, 파이썬, torchtext, pytorch, 파이토치, 전처리, data science, 데이터 분석, 딥러닝, 딥러닝 자격증, 머신러닝, 빅데이터]
categories: 
comments: true
published: true
---

Conv2d 


filter bias 


 spatial dimensions == depth 
  
 




https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html


![](https://blog.kakaocdn.net/dn/buTDig/btrUNWinaGI/Up3sBWkF1divFGgkP4DF2k/img.gif)

Naive Convolution [ 1 ]



![](https://blog.kakaocdn.net/dn/bpzdOE/btrUSukFrys/m8pk4doUidUAMASsLD5Ez0/img.gif)

Atrous Convolution [ 1 ]



![](https://blog.kakaocdn.net/dn/bjS7OO/btrUNqRBVaK/civUAMDkqkDr2Y1MYM1yb1/img.gif)

Transposed Convolution [ 1 ]


Unet 이해 

_class_torch.nn.Conv2d(_in_channels_, _out_channels_, _kernel_size_, _stride=1_, _padding=0_, _dilation=1_, _groups=1_, _bias=True_, _padding_mode='zeros'_, _device=None_, _dtype=None_)

![https://wandb.ai/ayush-thakur/dl-question-bank/reports/Intuitive-understanding-of-1D-2D-and-3D-convolutions-in-convolutional-neural-networks---VmlldzoxOTk2MDA](https://velog.velcdn.com/images/not12m10/post/1397fbde-00d8-4d8b-8c5c-62bf9acf7cad/image.gif)




![https://www.geeksforgeeks.org/apply-a-2d-convolution-operation-in-pytorch/](https://velog.velcdn.com/images/not12m10/post/f3c02918-fca1-4c29-8dde-ff0aa888ab76/image.gif)




----


## 1. 함성곱 신경망


(Global) average pooling 



1D 

시간축으로


2D

이미지 

3D

필터도 3차원을 가진 


3D 입략을 갖는 2D 합성곱 


fasion_size 28 by 28



batch norm 알고리즘 분석 
- https://eda-ai-lab.tistory.com/406


논문 읽고 분석하기 

- https://arxiv.org/abs/1505.04597



## FCN (Fully Convolutional Networks)

pixelwise prediction


- upsampling을 하여 dense map을 얻는 방법으로 **2가지 방법**이 더 소개된다.
-


- feature map 객채수를 동일하게 맞춰 준다 
- 고양이에 대한
- heatmap이 낮은 걸 upsamping 시킨다 -feature map 을 만들어 준다 
- 1. convlution 통해서 feature 추출하고 2 동일하게 맞추고 3번단계에서는 upsampling 시키고 4. 최종 featuremap과 정답과 학습을 한다. 


VGN 224 by 224 -(pooling)-> 112 by 112 -> 56 by 56 -> 28 by 28 -> 14 by 14 -> 7 by 7 -> 1 by 1 

coarse(대려적인) 정보를 얻고 있다. 

FCN fully connected layer 없고 1 by 1  슬라이드에 표현은 없지만 Relu 함수를 통해서 출력을 한다. 

pooling 대신에 stride 2 를 사용하여 줄여주는 경우도 있다. (확인해보기)

작은 픽셀 크기를 크게 만들면 성능이 떨어진다. 

FCN-32s, FCN-16s, FCN-8s 

conv conv pooling -> conv conv pooling -> conv conv conv pooling -> conv conv conv pooling -> 1 by 1 conv 

중간에 1 by 1 conv featuremap  사용한다 4번이 6번보 featureamap 조금더 중용한 정보를 얻는다(왜? 점점 줄어들어줄)

그래서 6번에서의 upsampling 한거랑 4번의 skip connection을 통해서 최종 출력을 한다. 



![](https://miro.medium.com/max/700/1*5LhYXkhBg6kwbR1zN5Eg8g.png)




![alt text](https://wikidocs.net/images/page/143443/FCN-16S.png)




![](https://wikidocs.net/images/page/143443/FCN-8S.png)



upsampin 하면 해상도가 떨어져 안좋아서 

Encoder 와 Decode 사용해서 

nnUnet 의료계에서 탑으로 자리 매김 하고 있다. 


## Encoder-Decoder 구조

고생상도 이미지를 Decoder 에 가지고 있다. 

Encoder 정보를 압축하고 

Decoder 정보를 풀어준다. 

Decoder 원래 정볼르 복원하면서 

upsamping techniques 

pooling 한걸 다시 unpooling  한거


transpose convlution

![](https://velog.velcdn.com/images%2Fhayaseleu%2Fpost%2F8abde504-c3b1-4a40-a17d-16ad230ccead%2F1_WpOcRWlofm0Z0EDUTKefzg.gif)![](https://velog.velcdn.com/images%2Fhayaseleu%2Fpost%2F36c9c660-27c3-40f3-a08c-335bf67610c1%2F1_34_365CJB5seboQDUrbI5A.gif)![](https://velog.velcdn.com/images%2Fhayaseleu%2Fpost%2F9457f703-acb1-443f-a450-8f1f834396dc%2F1_gXAcHnbTxmPb8KjSryki-g.gif)![](https://velog.velcdn.com/images%2Fhayaseleu%2Fpost%2F8abde504-c3b1-4a40-a17d-16ad230ccead%2F1_WpOcRWlofm0Z0EDUTKefzg.gif)


Unet 구조는 양쪽으로 대칭 구조 

각 step 마다 풀링 이 포함되어 있다. 
다운 샘플링 할때마다 2배식 채널수 증가 


convolution & ReLU (최근에 ReakyReLU 사용하는 추세)

Pooling()

64 128 256 512 1024 


bottlneck encoder 분분에 압축 되어 있다. 
2 by2 up convolution 




Decoder(Expanding Path) 심화

Transposed Convolution (Deconvolution)

업샘플링 + 학습




bottleneck 및 전체 흐름 

bottleneck 
인코더를 통해 가장 축소된 해상도 (가장 깊은 레이어)

1. BinaryCrossEntropy(BCE)
CrossEntropy 인데 Binary 인 경우 사용한다 픽셀이 foreground 인지 background 인지 

2. Dice Loss 
- 두 이미지 간의 유사도를 측정하는 손실 함수 
- p는 예측 값 (0~1 사이) prediction
- y는 실제 값 (0~1 사이) ground truth -> 실제 값
- prediction 과 ground truth 가 얼마 만큼 겹치는가? 

- overlap 

1. Focal Loss값




https://minimin2.tistory.com/179




Hard Example 가중치 

1. Hard Example Mining (OHEM, Online Hard Example Mining)
2. Weighted BCE 
3. Focal Loss

pixel 별로 분할 하는것이다. 


2.wieighted BCE는 적은 양에 클래스에 더 큰 가중치를 준다. 

3. 예측 확율 하드 example에 가중치를 준다 .  잘틀리는 것에 더 큰 가중치를 주어서 잘맞게 하지만 단점은 밸런스가 깨진다. 

Dice coefficient는 P (prediction) 과 y (ground truth) 각각 더하고 곱한 후


IoU (Intersection over Union) 일반적으로 사용되는 손실 함수적

Dice는 의료 영상 

Precision 

recall 실제  positive를 고려한다. 



● 정밀도(Precision): 정밀도는 긍정 값을 올바르게 분류하는 모델의 능력을 계산하는 데 사용됩니다. 이 값은 참 긍정을 예측된 긍정 값의 총수로 나눈 값입니다.

![](https://www.simplilearn.com/ice9/free_resources_article_thumb/5-precision.JPG)


