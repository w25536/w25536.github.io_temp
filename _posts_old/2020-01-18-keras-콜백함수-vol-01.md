---
layout: page
title: "[Keras] 콜백함수 (1) - 학습률(learning rate): ReduceLROnPlateau"
description: "[Keras] 콜백함수 (1) - 학습률(learning rate): ReduceLROnPlateau에 대하여 알아보겠습니다."
headline: "[Keras] 콜백함수 (1) - 학습률(learning rate): ReduceLROnPlateau에 대하여 알아보겠습니다."
tags: [keras, callback, learning-rate, reducelronplateau]
comments: true
published: true
categories: tensorflow
redirect_from:
  - deep-learning/keras-콜백함수-vol-01
typora-copy-images-to: ../images/2020-01-18
---





keras의 콜백함수인 `ReduceLROnPlateau`는 학습률이 개선되지 않을 때, 학습률을 동적으로 조정하여 학습률을 개선하는 효과를 기대할 수 있습니다. 경사하강법에 의하여 학습을 하는 경우 **Local Minima에 빠져버리게 되면, 더이상 학습률이 개선되지 않고 정체**되거나, 심하게 튀는 현상을 경험하신 분들이 많으실껍니다.



![2020-01-19-img-01](../images/2020-01-18/2020-01-19-img-01.png)

위의 그림처럼, Local Minima에 빠져버린 경우, 쉽게 빠져나오지 못하고 갇혀버리게 되는데, **이때 learning rate를 늘리거나 줄여주는 방법으로 빠져나오는 효과**를 기대할 수 있습니다.



Keras에는 콜백함수로 제공하고 있으며, `ReduceLROnPlateau`이 바로 그 역할을 합니다.



```python
from keras.callbacks import ReduceLROnPlateau

# 콜백 정의
reduceLR = ReduceLROnPlateau(
    monitor='val_loss',  # 검증 손실을 기준으로 callback이 호출됩니다
    factor=0.5,          # callback 호출시 학습률을 1/2로 줄입니다
    patience=10,         # epoch 10 동안 개선되지 않으면 callback이 호출됩니다
)

# model.fit 때 callback
history = model.fit(x_train, y_train, 
      validation_data=(x_valid, y_valid),
      epochs=EPOCH, 
      batch_size=BATCH_SIZE, 
      callbacks=[reduceLR], 
     )
```

