---
layout: page
title: "GoogLeNetì˜ Inception Module, 1x1 ì»¨ë³¼ë£¨ì…˜ì˜ ì˜ë¯¸ì™€ êµ¬í˜„"
description: "GoogLeNetì˜ Inception Module, 1x1 ì»¨ë³¼ë£¨ì…˜ì˜ ì˜ë¯¸ì™€ êµ¬í˜„ì— ëŒ€í•´ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤."
headline: "GoogLeNetì˜ Inception Module, 1x1 ì»¨ë³¼ë£¨ì…˜ì˜ ì˜ë¯¸ì™€ êµ¬í˜„ì— ëŒ€í•´ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤."
categories: python
tags: [python, íŒŒì´ì¬, pytorch, googlenet, inception module, pytorch implementation, Going Deeper with Convolutions, ì´ë¯¸ì§€ë„·, ImageNet, ë…¼ë¬¸ ì„¤ëª…, data science, ë°ì´í„° ë¶„ì„, ë”¥ëŸ¬ë‹, ë”¥ëŸ¬ë‹ ìê²©ì¦, ë¨¸ì‹ ëŸ¬ë‹, ë¹…ë°ì´í„°, í…Œë””ë…¸íŠ¸]
comments: true
published: true
typora-copy-images-to: ../images/2023-01-08
---

**Going Deeper with Convolutions(2015) Inception** ëª¨ë“ˆì— ëŒ€í•œ ë‚´ìš©ì…ë‹ˆë‹¤. í•´ë‹¹ ë…¼ë¬¸ì—ì„œëŠ” Inception Moduleì´ë¼ëŠ” ìƒˆë¡œìš´ neural network architecture ë¥¼ ê³µê°œí•˜ì˜€ìŠµë‹ˆë‹¤. ë…¼ë¬¸ì˜ ì œëª©ê³¼ ê°™ì´ Going Deeper ì¦‰ ë”ìš± ê¹Šì€ ì‹ ê²½ë§ ëª¨ë¸ì„ dimension reductionì´ ì ìš©ëœ Inception Moduleë¡œ ê°€ëŠ¥ì¼€ í•˜ì˜€ëŠ”ë°, ì´ë•Œ 1x1 ì»¨ë³¼ë£¨ì…˜(Convolution)ì„ ì ê·¹ í™œìš©í•˜ì˜€ìŠµë‹ˆë‹¤.

ì´ë•Œ í™œìš©í•œ 1x1 ì»¨ë³¼ë£¨ì…˜ì´ ì–´ë–¤ ì—­í• ì„ í•˜ì˜€ëŠ”ì§€ ì‚´í´ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.



ğŸ”¥ ë…¼ë¬¸ì€ ë‹¤ìŒì˜ ë§í¬ë¥¼ ì°¸ê³ í•´ ì£¼ì„¸ìš”!

- Going Deeper with Convolutions(2015) [**(ë§í¬)**](https://arxiv.org/pdf/1409.4842v1.pdf)



---



ë¨¼ì € ì•„ë˜ ê·¸ë¦¼ì€ ë…¼ë¬¸ì—ì„œ ë‚˜ì˜¨ ì´ˆê¸°(naive) ë²„ì „ì˜ Inception Module ì…ë‹ˆë‹¤. ê¶ê·¹ì ìœ¼ë¡œ ì•„ë˜ì˜ Inception Moduleì„ í™œìš©í•˜ì—¬ ì´ë¯¸ì§€ì˜ ì§€ì—­ì  íŠ¹ì„± ì¶”ì¶œì„ íš¨ê³¼ì ìœ¼ë¡œ ìˆ˜í–‰í•  ìˆ˜ ìˆë„ë¡ êµ¬ì¡°ë¥¼ ì„¤ê³„í•˜ì˜€ìŠµë‹ˆë‹¤.

í•˜ë‚˜ì˜ ì´ë¯¸ì§€ ì˜ì—­ì— ëŒ€í•˜ì—¬ 1x1, 3x3, 5x5 ì»¨ë³¼ë£¨ì…˜ê³¼ 3x3 Maxpooling ì¸µìœ¼ë¡œ íŠ¹ì„± ì¶”ì¶œì„ í•œ ë’¤ í•„í„°ì— ëŒ€í•œ concatenationì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

> ì´ˆê¸° ë²„ì „ì˜ Inception module

![Inception Module, naive version](../images/2023-01-08/inception-module-v1.png)



ìœ„ì˜ ê·¸ë¦¼ëŒ€ë¡œ Inception Moduleì„ êµ¬í˜„í•œ ì½”ë“œëŠ” ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.

```python
import torch
import torch.nn as nn
import torchsummary

class BaseConv2D(nn.Module):
    def __init__(self, in_channels, out_channels, **kwargs):
        super(BaseConv2D, self).__init__()
        self.conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, **kwargs)
        self.relu = nn.ReLU(inplace=True)
        
    def forward(self, x):
        return self.relu(self.conv(x))

        
class InceptionModuleV1(nn.Module):
    def __init__(self, in_channels, out_1x1, out_3x3, out_5x5, pool):
        super(InceptionModuleV1, self).__init__()
        self.conv1x1 = BaseConv2D(in_channels, out_1x1, kernel_size=1)
        self.conv3x3 = BaseConv2D(in_channels, out_3x3, kernel_size=3, padding='same')
        self.conv5x5 = BaseConv2D(in_channels, out_5x5, kernel_size=5, padding='same')
        self.pool = nn.Sequential(
            nn.MaxPool2d(kernel_size=3, stride=1, padding=1), 
            BaseConv2D(in_channels, pool, kernel_size=1, padding='same')
        )
    
    def forward(self, x):
        x1 = self.conv1x1(x)
        x2 = self.conv3x3(x)
        x3 = self.conv5x5(x)
        x4 = self.pool(x)
        return torch.cat([x1, x2, x3, x4], 1)
```

```python
# ì…ë ¥ ë§¤ê°œë³€ìˆ˜: in_channels, 1x1, 3x3, 5x5 ì»¨ë³¼ë£¨ì…˜ output í•„í„° ì‚¬ì´ì¦ˆ, Maxpooling output í•„í„° ì‚¬ì´ì¦ˆ
inception_module_V1 = InceptionModuleV1(192, 64, 128, 32, 32)
```

```python
# torchsummary ë¡œ 192 x 28 x 28 ì…ë ¥ì„ ì£¼ì—ˆì„ ë•Œì˜ íŒŒë¼ë¯¸í„° ì¶”ì •
torchsummary.summary(inception_module_V1, input_size=(192, 28, 28), device='cpu')
```

```
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 64, 28, 28]          12,352
              ReLU-2           [-1, 64, 28, 28]               0
        BaseConv2D-3           [-1, 64, 28, 28]               0
            Conv2d-4          [-1, 128, 28, 28]         221,312
              ReLU-5          [-1, 128, 28, 28]               0
        BaseConv2D-6          [-1, 128, 28, 28]               0
            Conv2d-7           [-1, 32, 28, 28]         153,632
              ReLU-8           [-1, 32, 28, 28]               0
        BaseConv2D-9           [-1, 32, 28, 28]               0
        MaxPool2d-10          [-1, 192, 28, 28]               0
           Conv2d-11           [-1, 32, 28, 28]           6,176
             ReLU-12           [-1, 32, 28, 28]               0
       BaseConv2D-13           [-1, 32, 28, 28]               0
================================================================
Total params: 393,472
Trainable params: 393,472
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.57
Forward/backward pass size (MB): 5.74
Params size (MB): 1.50
Estimated Total Size (MB): 7.82
----------------------------------------------------------------
```

28 x 28 í¬ê¸°ì˜ ì‚¬ì§„ 192ì¥ì„ ì…ë ¥ìœ¼ë¡œ ì£¼ì—ˆì„ ë•Œ í•™ìŠµ íŒŒë¼ë¯¸í„°ëŠ” **383k** ì •ë„ê°€ ë‚˜ì™”ìŠµë‹ˆë‹¤.

## 1x1 ì»¨ë³¼ë£¨ì…˜ì„ í™œìš©í•œ dimension reduction

ì´ì œ 1x1 Convolutionì„ ì ìš©í•œ Inception Moduleì„ ì•Œì•„ë³¼ ì°¨ë¡€ì…ë‹ˆë‹¤.

> dimension reductions ì´ ì ìš©ëœ Inception Module

![Inception Module with dimension reductions](../images/2023-01-08/inception-module-dimension-reductions.png)



ìœ„ì˜ ê·¸ë¦¼ì€ Inception Moduleì— dimension reductionsë¥¼ ì ìš©í•œ êµ¬ì¡°ë„ì…ë‹ˆë‹¤.

3x3, 5x5 ì»¨ë³¼ë£¨ì…˜ì„ í†µê³¼í•˜ê¸° ì „ì— **1x1 ì»¨ë³¼ë£¨ì…˜ì´ ì¶”ê°€**ëœ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, 3x3 Maxpoolingì„ í†µê³¼í•œ í›„ 1x1 ì»¨ë³¼ë£¨ì…˜ì„ í†µê³¼í•˜ëŠ” ê²ƒë„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì, ê·¸ëŸ¼ 1x1 ì»¨ë³¼ë£¨ì…˜ì„ ì¶”ê°€í•œ ì˜ë¯¸ëŠ” ë¬´ì—‡ì´ë©°, ê¶ê·¹ì ìœ¼ë¡œ ì–´ë–»ê²Œ GoogLeNetì˜ ëª¨ë¸ì˜ í•™ìŠµ ì„±ê³¼ë¥¼ ì˜¬ë¦´ ìˆ˜ ìˆì—ˆëŠ”ì§€ ì‚´í´ ë³´ê² ìŠµë‹ˆë‹¤.



> íŒŒë¼ë¯¸í„° ìˆ˜ ë¹„êµ

![1x1 Convolution Params](../images/2023-01-08/1x1convolution.png)

ìœ„ì˜ ê·¸ë¦¼ì—ì„œ 

1. ì²« ë²ˆì§¸ëŠ” **1x1 ì»¨ë³¼ë£¨ì…˜ì„ í™œìš©í•˜ì§€ ì•Šê³ ** 28x28 ì‚¬ì§„(íŠ¹ì„±ë§µ) 64ì¥ì„ ë§Œë“¤ì–´ë‚´ëŠ” ê²°ê³¼ì´ê³ 
2. ë‘ ë²ˆì§¸ëŠ” **1x1 ì»¨ë³¼ë£¨ì…˜ì„ í™œìš©í•˜ì—¬ dimension reductionì„ ìˆ˜í–‰** í›„ 28x28 ì‚¬ì§„(íŠ¹ì„±ë§µ) 64ì¥ì„ ë§Œë“¤ì–´ë‚´ëŠ” ê²°ê³¼ì…ë‹ˆë‹¤.

<u>*(ì»¨ë³¼ë£¨ì…˜ ì—°ì‚°ì‹œ zero-paddingì´ ì¶”ê°€ë˜ì–´ Feature Mapì˜ ì´ë¯¸ì§€ëŠ” ì¤„ì–´ë“¤ì§€ ì•Šì•˜ìŒì„ ì°¸ê³ í•´ ì£¼ì„¸ìš”!)*</u>



1. ì²« ë²ˆì§¸ëŠ” **160Mì˜ í•™ìŠµ íŒŒë¼ë¯¸í„°**ê°€ ì‚¬ìš©ë˜ê³ ,
2. ë‘ ë²ˆì§¸ëŠ” ì²« ë²ˆì§¸ ëŒ€ë¹„ í•™ìŠµ íŒŒë¼ë¯¸í„°ì˜ ê°œìˆ˜ê°€ **44.8M**ë¡œ í›¨ì”¬ ë” ì ìŠµë‹ˆë‹¤.ì´ìœ ëŠ” 1x1 ì»¨ë³¼ë£¨ì…˜ 32ê°€ ë¨¼ì € í•„í„°ì˜ ê°œìˆ˜ë¥¼ ì¤„ì´ê³ , ì´í›„ì— 5x5ì»¨ë³¼ë£¨ì…˜ 64ê°€ ìˆ˜í–‰ë˜ë©´ì„œ ì—°ìƒëŸ‰ì„ íšê¸°ì ìœ¼ë¡œ ì ˆì•½í•  ìˆ˜ ìˆì—ˆì§€ë§Œ, **ë™ì¼í•œ 28x28x64ì˜ ì•„ì›ƒí’‹**ì„ ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. 

ì´ë ‡ë“¯ **1x1 ì»¨ë³¼ë£¨ì…˜ì— í•„í„°ì˜ ê°¯ìˆ˜ë¥¼ ì¤„ì—¬ ì—°ì‚°ëŸ‰ì„ íšê¸°ì ìœ¼ë¡œ ê°ì†Œ**í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ê²ƒì´ ë°”ë¡œ **dimension reductionsì˜ í•µì‹¬**ì…ë‹ˆë‹¤. ì´ë ‡ê²Œ 1x1 ì»¨ë³¼ë£¨ì…˜ì—ì„œ í•„í„° ê°œìˆ˜ë¥¼ ì¤„ì¸ ë’¤ ë‹¤ì‹œ í‚¤ìš°ëŠ” êµ¬ì¡°ë¥¼ **BottleNeck** ì´ë¼ê³  ë¶€ë¥´ê¸°ë„ í•©ë‹ˆë‹¤.

ê²°êµ­, ì´ë ‡ê²Œ ì ˆì•½í•œ ì—°ì‚°ëŸ‰ ë•ë¶„ì— ë” ê¹Šì€ ëª¨ë¸ì„ ìƒì„±í•´ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. 



## Inception Module with dimension reductions êµ¬í˜„




```python
class InceptionModuleV2(nn.Module):
    def __init__(self, in_channels, out_1x1, out_3x3_reduce, out_3x3, out_5x5_reduce, out_5x5, pool):
        super(InceptionModuleV2, self).__init__()
        self.conv1x1 = BaseConv2D(in_channels, out_1x1, kernel_size=1)
        
        self.conv3x3 = nn.Sequential(
            # 1x1 Convolution
            BaseConv2D(in_channels, out_3x3_reduce, kernel_size=1),
            # 3x3 Convolution
            BaseConv2D(out_3x3_reduce, out_3x3, kernel_size=3, padding='same')
        )
        self.conv5x5 = nn.Sequential(
            # 1x1 Convolution
            BaseConv2D(in_channels, out_5x5_reduce, kernel_size=1),
            # 5x5 Convolution
            BaseConv2D(out_5x5_reduce, out_5x5, kernel_size=5, padding='same')
        )
        
        self.pool = nn.Sequential(
            # Maxpooling
            nn.MaxPool2d(kernel_size=3, stride=1, padding=1), 
            # 1x1 Convolution
            BaseConv2D(in_channels, pool, kernel_size=1, padding='same')
        )
    
    def forward(self, x):
        x1 = self.conv1x1(x)
        x2 = self.conv3x3(x)
        x3 = self.conv5x5(x)
        x4 = self.pool(x)
        return torch.cat([x1, x2, x3, x4], 1)
```

```python
# ì…ë ¥ ë§¤ê°œë³€ìˆ˜: in_channels, 1x1, 3x3 reduction, 3x3, 5x5 reduction, 5x5, Maxpool reduction
inception_module_V2 = InceptionModuleV2(192, 64, 96, 128, 16, 32, 32)
```

```python
# torchsummary ë¡œ 192 x 28 x 28 ì…ë ¥ì„ ì£¼ì—ˆì„ ë•Œì˜ íŒŒë¼ë¯¸í„° ì¶”ì •
torchsummary.summary(inception_module_V2, input_size=(192, 28, 28), device='cpu')
```

```
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 64, 28, 28]          12,352
              ReLU-2           [-1, 64, 28, 28]               0
        BaseConv2D-3           [-1, 64, 28, 28]               0
            Conv2d-4           [-1, 96, 28, 28]          18,528
              ReLU-5           [-1, 96, 28, 28]               0
        BaseConv2D-6           [-1, 96, 28, 28]               0
            Conv2d-7          [-1, 128, 28, 28]         110,720
              ReLU-8          [-1, 128, 28, 28]               0
        BaseConv2D-9          [-1, 128, 28, 28]               0
           Conv2d-10           [-1, 16, 28, 28]           3,088
             ReLU-11           [-1, 16, 28, 28]               0
       BaseConv2D-12           [-1, 16, 28, 28]               0
           Conv2d-13           [-1, 32, 28, 28]          12,832
             ReLU-14           [-1, 32, 28, 28]               0
       BaseConv2D-15           [-1, 32, 28, 28]               0
        MaxPool2d-16          [-1, 192, 28, 28]               0
           Conv2d-17           [-1, 32, 28, 28]           6,176
             ReLU-18           [-1, 32, 28, 28]               0
       BaseConv2D-19           [-1, 32, 28, 28]               0
================================================================
Total params: 163,696
Trainable params: 163,696
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.57
Forward/backward pass size (MB): 7.75
Params size (MB): 0.62
Estimated Total Size (MB): 8.95
----------------------------------------------------------------
```



- **ì´ˆê¸° ë²„ì „**: 28 x 28 í¬ê¸°ì˜ ì‚¬ì§„ 192ì¥ì„ ì…ë ¥ìœ¼ë¡œ ì£¼ì—ˆì„ ë•Œ í•™ìŠµ íŒŒë¼ë¯¸í„°ëŠ” **383k** ì •ë„ê°€ ë‚˜ì™”ìŠµë‹ˆë‹¤.
- **V2(dimension reductions ì ìš©)**: 28 x 28 í¬ê¸°ì˜ ì‚¬ì§„ 192ì¥ì„ ì…ë ¥ìœ¼ë¡œ ì£¼ì—ˆì„ ë•Œ í•™ìŠµ íŒŒë¼ë¯¸í„°ëŠ” **163k** ì •ë„ê°€ ë‚˜ì™”ìŠµë‹ˆë‹¤.

í™•ì‹¤íˆ íŒŒë¼ë¯¸í„° ê°œìˆ˜ê°€ í° ì°¨ì´ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ì•„ë˜ëŠ” Inception Module V1, V2ë¥¼ í†µê³¼í•œ ê²°ê³¼ì˜ Shape ì…ë‹ˆë‹¤.

```python
# ë”ë¯¸ ë°ì´í„° ìƒì„± (192x28x28)
dummy_input = torch.randn(size=(1, 192, 28, 28))
# V1 í†µê³¼
y1 = inception_module_V1(dummy_input)
# V2 í†µê³¼
y2 = inception_module_V2(dummy_input)
# Shape ì¶œë ¥
print(y1.shape, y2.shape)
```

```
# ì¶œë ¥ ê²°ê³¼
torch.Size([1, 256, 28, 28]) torch.Size([1, 256, 28, 28])
```



ê²°ê³¼ëŠ” V1, V2 ëª¨ë‘ ë™ì¼í•œ Shapeê°€ ì¶œë ¥ë¨ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¦‰, **ê²°ê³¼ë¬¼ì˜ ShapeëŠ” ë™ì¼**í•˜ë‚˜ íŒŒë¼ë¯¸í„° ì°¨ì´ê°€ ì•½ **220k** ì •ë„ ë‚©ë‹ˆë‹¤.
